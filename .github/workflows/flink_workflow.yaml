name: Run flink Command on Push

on:
  push:
    branches:
      - main
    paths:
      - '**/*.sql'

jobs:
  cancel-existing-jobs:  # New job to cancel existing jobs
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Find SQL files
      id: find_sql_files
      run: |
        sql_files=$(git show --name-only HEAD | grep "\.sql$")
        echo "::set-output name=sql_files::$sql_files"

    - name: SSH into remote instance and cancel jobs
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ec2-18-207-123-14.compute-1.amazonaws.com
        username: ec2-user
        key: ${{ secrets.SSH_PRIVATE_KEY }}
        port: 22
        script: |
          # Retrieve SQL files from output
          sql_files="${{ steps.find_sql_files.outputs.sql_files }}"

          if [ -n "$sql_files" ]; then
            # Ensure Flink installation path is correct (optional, move if needed)
            FLINK_JOB_IDS=/home/ec2-user/flink_ci_cd_pipeline/job_ids

            # Pull latest changes from the Git repository (optional)
            cd /home/ec2-user/flink_ci_cd_pipeline  # Adjust path if needed
            git pull origin main

            # Loop through files
            for file in $sql_files; do
              # Extract filename without extension
              sql_file_name=$(basename "$file" .sql)

              # Cancel existing jobs (if any)
              curl -X PATCH "http://localhost:8081/jobs/?mode=cancel&recursive=true&filter=name~'$sql_file_name'"
            done
          fi

  run-flink-command:  # New job to run Flink command
    runs-on: ubuntu-latest
    needs: cancel-existing-jobs  # This job depends on cancel-existing-jobs completing first
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Find SQL files  # Can potentially re-use output from previous job
      id: find_sql_files
      run: |
        sql_files=$(git show --name-only HEAD | grep "\.sql$")
        echo "::set-output name=sql_files::$sql_files"

    - name: SSH into remote instance and run command
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ec2-18-207-123-14.compute-1.amazonaws.com
        username: ec2-user
        key: ${{ secrets.SSH_PRIVATE_KEY }}
        port: 22
        script: |
          # Retrieve SQL files from output
          sql_files="${{ steps.find_sql_files.outputs.sql_files }}"

          if [ -n "$sql_files" ]; then
            # Ensure Flink installation path is correct (optional, move if needed)
            FLINK_HOME=/home/ec2-user/flink/flink-1.18.0
            FLINK_SQL_FILES=/home/ec2-user/flink_ci_cd_pipeline

            for file in $sql_files; do
              # Remove file extension to get the SQL file name
              sql_file_name=$(basename "$file" .sql)
              
              # Run Flink command and capture job ID
              job_id=$(sudo $FLINK_HOME/bin/sql-client.sh -f $FLINK_SQL_FILES/$file -e 10.0.6.133:8081 2>&1 | grep 'Job ID' | awk '{print $3}')
              
              # Create new file with job ID
              echo "$job_id" > $FLINK_JOB_IDS/$sql_file_name
            done
            
            # Commit and push changes to the Git repository
            git add .
            git commit -m "Update job_id directory and submit new jobs"
            git push https://${{ secrets.GH_USERNAME }}:${{ secrets.GH_TOKEN }}@github.com/${{ secrets.GH_USERNAME }}/flink_ci_cd_pipeline.git
          fi
